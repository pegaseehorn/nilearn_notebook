{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3fe2c39d",
   "metadata": {},
   "source": [
    "# Dataset handling\n",
    "## Importing NiLearn:\n",
    "\n",
    "Like always in python we start by importing the necessary packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c5113e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nilearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e87be37",
   "metadata": {},
   "source": [
    "## Downloading / importing the dataset:\n",
    "\n",
    "Then we download the dataset to work with during this session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78836346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/sophiahaake/nilearn_data/fMRI-language-localizer-demo-dataset\n"
     ]
    }
   ],
   "source": [
    "# Download language localizer demo dataset.\n",
    "from nilearn.datasets import fetch_language_localizer_demo_dataset\n",
    "\n",
    "data = fetch_language_localizer_demo_dataset(legacy_output=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9bbcb03",
   "metadata": {},
   "source": [
    "Alternatively, we can import a dataset from our local hard disk by pointing to the nifti files directly or importing them as a nifti image object via the python package 'nibabel'.\n",
    "\n",
    "Here we show demo code displaying how to input your own BIDS-formatted dataset from your hard disk via nibabel.\n",
    "Nifti images can be 3D or 4D. A 4D nifti image may for instance represent a time series of 3D images, or contain multiple brain volumes (e.g. from subjects). It can be a list of file names, if these contain 3D information.\n",
    "\n",
    "result_img is a 4D in-memory image, containing the data of both subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b607235",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our BIDS-formatted dataset folder contains subject1.nii and subject2.nii\n",
    "\n",
    "# First, we download the necessary packages for using nibabel:\n",
    "import os\n",
    "import numpy as np\n",
    "from nibabel.testing import data_path\n",
    "import nibabel as nib\n",
    "\n",
    "# Then, we specifiy the path to the image, as well as the image name:\n",
    "example_filename = os.path.join(data_path, ['~dataset/subject1.nii', '~dataset/subject2.nii'])\n",
    "\n",
    "# Then, we load the image with the load function from nibabel; this results in a class of object called a 'Nifti1mage object', specifically created to work with MRI data in Python:\n",
    "img = nib.load(example_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab22991",
   "metadata": {},
   "source": [
    "## Matching multiple files:\n",
    "Suppose the dataset folder contains subject_01.nii, subject_03.nii, and subject_03.nii. You can use a python capability called 'globbing' to use a single expression to load multiple datasets.\n",
    "'~dataset/subject_*.nii' is such a glob expression matching all filenames. The code would change as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83b6322",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_filename = os.path.join(data_path, '~dataset/subject_*.nii')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf03e65",
   "metadata": {},
   "source": [
    "## Sanity check:\n",
    "Now we can check, whether the dataset was correctly downloaded by checking its location on the hard disk and disply a short description of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4b8b33ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/sophiahaake/nilearn_data/fMRI-language-localizer-demo-dataset\n",
      ".. _language_localizer_dataset:\n",
      "\n",
      "language localizer demo dataset\n",
      "===============================\n",
      "\n",
      "Access\n",
      "------\n",
      "See :func:`nilearn.datasets.fetch_language_localizer_demo_dataset`.\n",
      "\n",
      "Notes\n",
      "-----\n",
      "10 subjects were scanned with fMRI during a \"language localizer\"\n",
      "where they (covertly) read meaningful sentences (trial_type='language')\n",
      "or strings of consonants (trial_type='string'),\n",
      "presented one word at a time at the center of the screen (rapid serial visual presentation).\n",
      "\n",
      "The functional images files (in derivatives/)\n",
      "have been preprocessed (spatially realigned and normalized into the :term:`MNI` space).\n",
      "Initially acquired with a :term:`voxel` size of 1.5x1.5x1.5mm,\n",
      "they have been resampled to 4.5x4.5x4.5mm to save disk space.\n",
      "\n",
      "https://osf.io/k4jp8/\n",
      "\n",
      "Content\n",
      "-------\n",
      "    :'data_dir': Path to downloaded dataset.\n",
      "    :'downloaded_files': Absolute paths of downloaded files on disk\n",
      "\n",
      "\n",
      "References\n",
      "----------\n",
      "\n",
      "\n",
      "License\n",
      "-------\n",
      "ODC-BY-SA\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(data.data_dir)\n",
    "print(data.description)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NiLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
