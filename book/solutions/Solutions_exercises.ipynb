{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7edb3f8e",
   "metadata": {},
   "source": [
    "# Exercise solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7e4b05c",
   "metadata": {},
   "source": [
    "## Exercise 1 - Group 1:\n",
    "In our analysis we compare the condition 'language' with thecondition  'string'. We do this by utilising a contrast.\n",
    "1. What do those conditions mean in the context of the experiment?\n",
    "2. Where in the code is the contrast specified?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dac9e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn import plotting # import plotting here\n",
    "\n",
    "ncols = 3\n",
    "nrows = ceil(len(models) / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 4.5))\n",
    "axes = np.atleast_2d(axes)\n",
    "model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "for midx, (model, imgs, events, confounds) in enumerate(model_and_args):\n",
    "    # fit the GLM\n",
    "    model.fit(imgs, events, confounds)\n",
    "    # compute the contrast of interest\n",
    "    zmap = model.compute_contrast(\"string\")  # language - string\" or \"language\" or \"string\"\n",
    "    plotting.plot_glass_brain(\n",
    "        zmap,\n",
    "        colorbar=False,\n",
    "        threshold=p001_unc,\n",
    "        title=f\"sub-{model.subject_label}\",\n",
    "        axes=axes[int(midx / ncols), int(midx % ncols)],\n",
    "        plot_abs=False,\n",
    "        display_mode=\"x\",\n",
    "        cmap=\"bwr\",\n",
    "    )\n",
    "fig.suptitle(\"subjects z_map language network (unc p<0.001)\")\n",
    "plotting.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b451a5",
   "metadata": {},
   "source": [
    "3. First, try to change the contrasts so that condition 'language' is compared to the baseline. Then do the same for condition 'string'. Plot both results and compare the plots. What changes can you observe? Interpret them.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c138742",
   "metadata": {},
   "outputs": [],
   "source": [
    "zmap = second_level_model.compute_contrast(\n",
    "    first_level_contrast=\"string\" # \"language - string\" or \"language\" or \"string\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abfe803a",
   "metadata": {},
   "source": [
    "4. Can you write down design matrixes for each condition? The design matrix for subject one in figure 1 can help you with that.\n",
    "\n",
    "    If you can, you can also plot those first level analysis design matrixes with NiLearn. The function can be looked up in the documentation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13babab7",
   "metadata": {},
   "source": [
    "## Exercise 2 - Group 2:\n",
    "In figure 2 you can see the z-maps of our participants for an uncorrected p-value of < 0.001.\n",
    "1. Change the p-value to a different one and re-generate the figure.\n",
    "2. What changes?\n",
    "3. What is a good value for the uncorrected p-value and why? Remember the multiple testing problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b195ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "p001_unc = norm.isf(0.001) # the p-value has to be transformed in a z-value before it can be used in other functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc7352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to change the p-value only in the first-level analysis\n",
    "from math import ceil\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nilearn import plotting # import plotting here\n",
    "\n",
    "ncols = 3\n",
    "nrows = ceil(len(models) / ncols)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=(8, 4.5))\n",
    "axes = np.atleast_2d(axes)\n",
    "model_and_args = zip(models, models_run_imgs, models_events, models_confounds)\n",
    "for midx, (model, imgs, events, confounds) in enumerate(model_and_args):\n",
    "    # fit the GLM\n",
    "    model.fit(imgs, events, confounds)\n",
    "    # compute the contrast of interest\n",
    "    zmap = model.compute_contrast(\"language-string\")\n",
    "    plotting.plot_glass_brain(\n",
    "        zmap,\n",
    "        colorbar=False,\n",
    "        threshold=p001_unc, # change p001_unc to a z-value matching to your p-value, e.g. norm.isf(0.05) for p = 0.05\n",
    "        title=f\"sub-{model.subject_label}\",\n",
    "        axes=axes[int(midx / ncols), int(midx % ncols)],\n",
    "        plot_abs=False,\n",
    "        display_mode=\"x\",\n",
    "        cmap=\"bwr\",\n",
    "    )\n",
    "fig.suptitle(\"subjects z_map language network (unc p<0.001)\") # correct the plot label\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71838e7a",
   "metadata": {},
   "source": [
    "## Exercise 3 - Group 3:\n",
    "As you can see in figure one, we are currently running our analysis on four participants.\n",
    "1. Can you point out the section of code that is responsible for this sub-selection of participants? How many participants did our dataset originally include?\n",
    "2. Try to re-run the analysis with a different number of participants and plot the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6194e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn.glm.first_level import first_level_from_bids\n",
    "\n",
    "task_label = \"languagelocalizer\"\n",
    "(\n",
    "    models,\n",
    "    models_run_imgs,\n",
    "    models_events,\n",
    "    models_confounds,\n",
    ") = first_level_from_bids(\n",
    "    data.data_dir,                     \n",
    "    task_label,\n",
    "    img_filters=[(\"desc\", \"preproc\")],\n",
    "    n_jobs=2, # controls how many tasks are run in parallel (i.e., how many CPU cores are used)\n",
    "    space_label=\"\",\n",
    "    sub_labels=[\"01\", \"02\", \"03\", \"04\"],  # comment to run all subjects or add for example \"05\", \"10\" to add also subject 5 and 10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50a66a3",
   "metadata": {},
   "source": [
    "3. It takes a lot of time to run the analysis on many participants, can the processing time be reduced? Please find the specific parameter and try out different values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582da20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model = SecondLevelModel(smoothing_fwhm=8.0, n_jobs=2) # n_jobs controls how many tasks are run in parallel (i.e., how many CPU cores are used)\n",
    "second_level_model = second_level_model.fit(second_level_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605a5448",
   "metadata": {},
   "source": [
    "## Exercise 4 - Group 4:\n",
    "What is the p-value we use in our second level analysis? (Hint: look at figure 2)\n",
    "1. Where in the code is the parameter that sets this value? Can you change it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3010c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "p001_unc = norm.isf(0.001) # the p-value (0.001) has to be transformed in a z-value (norm.isf) before it can be used in other functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9c84f2",
   "metadata": {},
   "source": [
    "2. Try out a few different values and plot them. What changes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5fadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to change the p-value only in the second-level analysis\n",
    "plotting.plot_glass_brain(\n",
    "    zmap,\n",
    "    colorbar=True,\n",
    "    threshold=p001_unc, # change p001_unc to a z-value matching to your p-value, e.g. norm.isf(0.05) for p = 0.05\n",
    "    title=\"Group language network (unc p<0.001)\", # correct the plot label\n",
    "    plot_abs=False,\n",
    "    display_mode=\"x\",\n",
    "    figure=plt.figure(figsize=(5, 4)),\n",
    "    cmap=\"bwr\",\n",
    ")\n",
    "plotting.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e3f3bf",
   "metadata": {},
   "source": [
    "3. What is a good p-value for the second level analysis? Keep the multiple testing problem in mind.\n",
    "4. We use an uncorrected p-value. What methods can we use to correct a p-value? In question 6 we will see how we can implement those correction strategies in NiLearn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f6ff8",
   "metadata": {},
   "source": [
    "## Exercise 5 - Group 5:\n",
    "In our second level analysis we can specify a smoothing parameter \"smoothing_fwhm\".\n",
    "1. Where can we specifiy this parameter in the code? What is the purpose of this parameter? (Hint: use the documentation)\n",
    "2. Try a few different values for the smoothing parameter an plot them. What changes in the plots?\n",
    "3. What are the advantages/disadvantages is using small/large smoothing parameters? Which values would you prefer in which situation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484e4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_level_model = SecondLevelModel(smoothing_fwhm=20.0, n_jobs=2) # there is the smoothing parameter\n",
    "second_level_model = second_level_model.fit(second_level_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a1844a",
   "metadata": {},
   "source": [
    "## Exercise 6 (Advanced, for Python pros) - Group 6:\n",
    "In our analysis we manually decreased the p-value to 0.001 to adjust the error-rate for the multiple testing problem.\n",
    "1. Can we use NiLearn to do this automatically? What are the two functions that NiLearn provides for that? (Hint: look at the documentation)\n",
    "2. What is the best correction method? Extend the code so that this correction method is applied.\n",
    "3. What effect does the correction have on a p-value of 0.05? Plot two second level analysis output plots side-by-side, one with the uncorrected p-value and the other for the corrected p-value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7757699",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_zmap,threshold_value = nilearn.glm.thresholding.threshold_stats_img(zmap, alpha=0.05, height_control='fpr') # you can change fpr also to 'bonferroni' etc.\n",
    "plotting.plot_glass_brain(\n",
    "    corrected_zmap, # the corrected_zmap must be included\n",
    "    colorbar=True,\n",
    "    threshold=threshold_value, # the threshold is replaced by the corrected value\n",
    "    title=\"Group language network (unc p<0.001)\", # correct the plot label\n",
    "    plot_abs=False,\n",
    "    display_mode=\"x\",\n",
    "    figure=plt.figure(figsize=(5, 4)),\n",
    "    cmap=\"bwr\",\n",
    ")\n",
    "plotting.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
